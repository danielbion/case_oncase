---
title: 'Case OnCase'
output: html_notebook
---

Load libraries

```{r, message = FALSE, warning=FALSE}
dir = 'C:/Projects/case_oncase/case_oncase'
setwd(dir)

library(tidyverse)
library(jsonlite)
library(ggthemes)
library(httr)
library(gridExtra)
library(mlr)
options(warn=-1)

```


Load the database

```{r message=FALSE, warning=FALSE}
recipesJson = stream_in(file('receitas.json'))
recipes = as_tibble(recipesJson)
```

Remove duplicated data, outliers, data with missing values

```{r message=FALSE, warning=FALSE}
recipes = recipes[!duplicated(recipes[,c('title', 'desc', 'date')]),]

recipes$date = as.Date(recipes$date)
recipes$numOfIngredients = lengths(recipes$ingredients)
recipes$numOfDirections = lengths(recipes$directions)

recipes = recipes %>% 
  filter(lengths(categories) > 0) %>%
  filter(!is.na(calories)) %>%
  filter(calories < sd(calories, na.rm=TRUE) * 3)

```


#1. Which categories belong to the most caloric foods?

```{r message=FALSE, warning=FALSE}
rankCalories = recipes %>%
  unnest(categories) %>%
  group_by(categories) %>% 
  summarise(Median = median(calories), Count = n()) %>%
  arrange(desc(Median)) %>%
  filter(Count > 1) %>%
  top_n(20, Median)
  
ggplot(rankCalories, aes(x = reorder(categories, Median), 
  y = Median, fill = Median)) +
  geom_bar(stat='identity') + 
  geom_text(aes(x = categories, y = 100, label = Median), hjust=0, colour = 'white') +
  labs(x = 'Categories') +
  coord_flip() +
  scale_fill_continuous(low="orange", high="red") +
  theme_few()

```

#2. What are the top 10 ingredients contained in the most calorie recipes?
```{r message=FALSE, warning=FALSE}

rankCalories = recipes %>%
  unnest(ingredients) %>%
  group_by(ingredients) %>%
  summarise(Median = median(calories), Count = n()) %>%
  arrange(desc(Median)) %>%
  top_n(10, Median)

rankCalories %>% select('ingredients')
```

#3. If you had to recommend 3 recipes based on the data, what would they be?

Depending on the client profile:

* Healthy
* Quick and easy
* Lunch/Breakfast/Dinner

A recommendation for me:

* Balanced amount of calories;
* Sodium intake below daily recommended (2000);
* Amount of protein above the median;
* Rating in the best quantile;
* Less than 5 ingredients for preparation;
* Removed drinks.
```{r message=FALSE, warning=FALSE}

rankRating = recipes %>%
  filter(calories >= median(calories)/1.5 
         & calories <= median(calories) * 1.5
         & sodium < 2000
         & protein >= 9
         & lengths(ingredients) < 5
         & !str_detect(categories, 'Drink')
         & rating >= 4.38)


rankRating = rankRating %>% 
  arrange(desc(protein), numOfDirections) %>%
  select('title','numOfIngredients', 'numOfDirections', 'protein', 'calories', 'fat')

rankRating[1:3, ]
```
#4. Does any feature present in the data determine the high grade of a recipe?
* The more detailed/explained the recipe, better is the rating.

```{r message=FALSE, warning=FALSE}
plotCalories = ggplot(recipes, aes(x = rating, y = calories)) +
  geom_bar(stat = "summary", fun.y = "mean") 

plotFat = ggplot(recipes, aes(x = rating, y = fat)) +
  geom_bar(stat = "summary", fun.y = "mean") 

plotProtein = ggplot(recipes, aes(x = rating, y = protein)) +
  geom_bar(stat = "summary", fun.y = "mean") 

plotSodium = ggplot(recipes, aes(x = rating, y = sodium)) +
  geom_bar(stat = "summary", fun.y = "mean") 

plotIngredients = ggplot(recipes, aes(x = rating, y = numOfIngredients)) +
  geom_bar(stat = "summary", fun.y = "mean") 

plotDirections = ggplot(recipes, aes(x = rating, y = numOfDirections)) +
  geom_bar(stat = "summary", fun.y = "mean") 

grid.arrange(plotCalories, plotFat, plotProtein, plotSodium, plotIngredients, plotDirections, ncol=3)


```


#5. Considering the categories of the top 100 recipes under review, how many recipes are currently on the site https://www.epicurious.com for each category

```{r message=FALSE, warning=FALSE}

removeAccent = function(str){
  symbols = c(acute = '·ÈÌÛ˙¡…Õ”⁄˝›', grave = '‡ËÏÚ˘¿»Ã“Ÿ', circunflex = '‚ÍÓÙ˚¬ Œ‘€',
      tilde = '„ı√’Ò—', umlaut = '‰ÎÔˆ¸ƒÀœ÷‹ˇ', cedil = 'Á«')
  
  nudeSymbols = c(acute = 'aeiouAEIOUyY',grave = 'aeiouAEIOU',circunflex = 'aeiouAEIOU',
      tilde = 'aoAOnN',umlaut = 'aeiouAEIOUy',cedil = 'cC')
  
  punct = c(',', '\\.', '\\?', '-', ':', ';', '/')
  for (i in 1:length(punct)){
      str = gsub(punct[i], ' ', str)
  }
  punct = c('\'', '&', '+', '#', '\uFFFD')
  for (i in 1:length(punct)){
      str = gsub(punct[i], '', str)
  }
  return(chartr(paste(symbols, collapse = ''), paste(nudeSymbols, collapse = ''), str))
}

searchByCategory = function(category){
  category = removeAccent(category)
  category = gsub(' ', '%20', category)
  content = GET(paste0('https://www.epicurious.com/search/', category))
  startIndex = str_locate(content,'<span class="matching-count" data-reactid="39">')[2] + 1
  filteredContent1 = substring(content, startIndex)
  
  endIndex = str_locate(filteredContent1,'</span>')[1] - 1
  text = substring(filteredContent1, 0, endIndex)
  count = as.numeric(gsub(',', '', text))
  return (count)
}

topRecipesByRating = recipes %>%
  arrange(desc(rating))

topRecipesByRating = topRecipesByRating[1:100,]

categories = topRecipesByRating %>%
  select('categories') %>% 
  unnest(categories)

categories = categories[!duplicated(categories),]


#Uncoment to run the search
#categories$count = sapply(categories$categories, searchByCategory)
#saveRDS(categories, 'categories.rds')
categories <- readRDS('categories.rds')
categories %>% arrange (desc(count))

```

#6. Build a classifier to recommend tags (categories) for recipes:

* We have a multilabel classification problem, we need to train a classifier for each label.
```{r message=FALSE, warning=FALSE}

removeSpace = function(str){
  return (gsub(' ', '', str))
}

removeNumbers = function(str){
  numbers = '0123456789'
  return(removeSpace(chartr(numbers, paste(rep(' ', nchar(numbers)), collapse = ''), str)))
}

# Prepare the dataset
recipesSample = recipes[sample(nrow(recipes), 1000), ]

recipesSample$categoriesUpper = NA
recipesSample$categoriesUpper = lapply(recipesSample$categories, toupper)
recipesSample$categoriesUpper = lapply(recipesSample$categoriesUpper, removeAccent)
recipesSample$categoriesUpper = lapply(recipesSample$categoriesUpper, removeNumbers)


labels = recipesSample %>%
  select('categoriesUpper') %>% 
  unnest(categoriesUpper)


# Select categories with at least 10 recipes
labels = labels %>% add_count(categoriesUpper) %>% filter(n >= 10) %>% select('categoriesUpper')
labels = labels[!duplicated(labels$categoriesUpper),]
labels = labels$categoriesUpper


df = data.frame(matrix(ncol = length(labels), nrow = 0))
names(df) = labels


for(i in 1:nrow(recipesSample)){
   for(j in 1:length(labels)){
       df[i, j] = str_detect(string = recipesSample$categoriesUpper[i], pattern = labels[[j]])
   }
}


recipesSample = recipesSample %>%
  select('fat', 'calories', 'protein', 'rating', 'sodium', 'numOfIngredients', 'numOfDirections')
data = cbind(recipesSample, df)
```

Start the predictions
```{r message=FALSE, warning=FALSE}
# Start the prediction task
task = makeMultilabelTask(data = data, target = unlist(labels))
n = getTaskSize(task)
train.set = sample(n, round(n * 0.75))
test.set = which(!(1:n %in% train.set))


binary.learner = makeLearner("classif.rpart", predict.type = "prob")
lrn = list()
lrn[[1]] = makeMultilabelBinaryRelevanceWrapper(binary.learner)
lrn[[2]] = makeMultilabelClassifierChainsWrapper(binary.learner)
lrn[[3]] = makeMultilabelDBRWrapper(binary.learner)


model = list()
prediction = list()


model[[1]] = train(lrn[[1]], task, subset = train.set)
prediction[[1]] = predict(model[[1]], task = task, subset = test.set)


model[[2]] = train(lrn[[2]], task, subset = train.set)
prediction[[2]] = predict(model[[2]], task = task, subset = test.set)


model[[3]] = train(lrn[[3]], task, subset = train.set)
prediction[[3]] = predict(model[[3]], task = task, subset = test.set)


perf = c()
# Overall performance
perf[1] = performance(prediction[[1]], measures = list(multilabel.acc))
perf[2] = performance(prediction[[2]], measures = list(multilabel.acc))
perf[3] = performance(prediction[[3]], measures = list(multilabel.acc))


best.index = which.max(perf)
best.model = model[[best.index]]
best.prediction = prediction[[best.index]]
best.perf = perf[best.index]

```
Show a sample result

```{r message=FALSE, warning=FALSE}
getResultTable = function(predictionNames){
  truth = predictionNames[str_detect(predictionNames, 'truth')]
  truth = unlist(strsplit(truth, '\\.'))
  truth = truth[which(truth != 'truth')]
  
  
  response = predictionNames[str_detect(predictionNames, 'response')]
  response = unlist(strsplit(response, '\\.'))
  response = response[which(response != 'response')]
  
  
  labels = c(truth, response)
  labels = labels[!duplicated(labels)]
   
  
  result = data.frame(matrix(NA, nrow =  length(labels), ncol =2))
  row.names(result) = labels
  names(result) = c('truth', 'response')
  result[which(row.names(result) %in% truth), 'truth'] = 'X'
  result[which(!row.names(result) %in% truth), 'truth'] = ''
  result[which(row.names(result) %in% response), 'response'] = 'X'
  result[which(!row.names(result) %in% response), 'response'] = ''
  return (result)
}


predictionExample = best.prediction$data[sample(nrow(best.prediction$data), 1),]
predictionNames = names(predictionExample[which(predictionExample == TRUE)])
result = getResultTable(predictionNames)
as.data.frame(result)


```

